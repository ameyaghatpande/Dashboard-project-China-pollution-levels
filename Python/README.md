### This folder contains the python scripts used to clean and explore the data required for Visualization project

<p><strong>china_five_city_workbook</strong>: This Jupyter Notebook reads data from the Raw-Data folder, and the csv files read in this workbook are the cities yearly sheet (e.g. Beijing_2008_2.5.csv, Beijing_2009_2.5.csv). We performed the same data cleaning steps for each sheet (read from the 4th row, eliminate the -999/missing value, and drop the QC Name column). Afterwards, we concatenated all 35 csv into a dataset (china_all.csv, found in the Clean-Data folder). </p>
<p> The second part of this Jupyter Notebook is to group by date. The objective of this part is to create a dataset based on the whole china_all.csv dataset and find out what is the average daily value for each date for each city. We first tried to determine whether the Date (LST) column was a datetime type, if so, we can manipulate the column easily. However, it was an Object type. We noticed each row had the Year, Month, and Day columns. Therefore, we created a new column by concatenating the three columns. Once the new Date column was created, we dropped the columns not needed (Parameter, Date (LST), Year, Month, Day, Hour, Unit, and Duration). Then we grouped by Site (i.e. city) and Date. The dataframe is exported to city_date.csv, found in the Clean-Data folder. </p>
